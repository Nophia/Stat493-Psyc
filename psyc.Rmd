---
title: "Final project"
author: "Jialin"
date: "3/4/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(readxl)
library(tidyverse)
library(GGally)
library(MASS)
library(leaps)
library(car)
library(randomForest)
library(splines)
```

get the data

```{r}
data <- read_excel("data.xls")
data$gender=as.factor(data$gender)
data$group=as.factor(data$group)

data1<-data%>%
  mutate(selfcom=(self_kindness+self_judgment_reverse_scored+common_humanity+isolation_reverse_scored+mindfulness+over_identification_reverse_scored)/6)%>%
  dplyr::select(-self_compassion)
```

Separate the data into a training and testing dataset

```{r}
set.seed(323)
partition<-createDataPartition(data1$depression,p=0.7,list = FALSE)
psyc.train<-data1[partition,]
psyc.test<-data1[-partition,]
```

```{r, echo=FALSE}
ggpairs(data=psyc.train, progress = FALSE)
```

4. Perform Forward Selection.

```{r} 
model_base <- lm(depression ~ 1, data = psyc.train)
model_full <- lm(depression ~ ., data = psyc.train)
stepAIC(model_base, scope = list(upper = model_full, lower = model_base), direction = "forward", trace = FALSE)$anova
```

5. Perform Backward Elimination.

```{r}
stepAIC(model_full, direction = "backward", trace = FALSE)$anova
```

6. Perform Mixed Selection.

```{r}
stepAIC(model_base, scope = list(upper = model_full, lower = model_base), direction = "both", trace = FALSE)$anova
stepAIC(model_full, scope = list(upper = model_full, lower = model_base), direction = "both", trace = FALSE)$anova
```

7. Run an all-subsets selection technique.

```{r}
model_subset <- regsubsets(depression ~ ., nbest = 3, data = psyc.train)
plot(model_subset)
```

linear regression model:

```{r}
model1 <- lm(depression ~ group + age + anxious_attachment + avoidant_attachment + isolation_reverse_scored + over_identification_reverse_scored + 
    anxiety , data = psyc.train)

summary(model1)
```

remove outlier in training data:

```{r}
psyc.train.new <-psyc.train %>% 
  mutate(leverage = hatvalues(model1),
         studres = studres(model1),
         cooks = cooks.distance(model1),
         id = row_number())

ggplot(data = psyc.train.new) + 
  geom_point(mapping=aes(x = id, y = cooks)) + 
  ggtitle("Leverage vs. ID")+ xlab("ID Code") + ylab("Leverage")+
  ggrepel::geom_text_repel(aes(y=cooks, x=id, label=id),
                           data = psyc.train.new %>% 
                             filter(leverage>0.4|studres>2|studres< -2|cooks> 0.3))

psyc.train1<-psyc.train[-c(65, 276), ]
```

regression model using testing data:

```{r}
model2 <- lm(depression ~ group + age + anxious_attachment + avoidant_attachment + isolation_reverse_scored + over_identification_reverse_scored + 
    anxiety , data = psyc.train1)
summary(model2)
pred1 <- predict(model2, newdata = psyc.test)
mean((psyc.test$depression-pred1)^2)
```

Repeated k-fold cross validation:

```{r}
set.seed(323)
partition<-createDataPartition(data1$depression,p=0.7,list = FALSE)
psyc.train<-data1[partition,]
psyc.test<-data1[-partition,]

train.control <- trainControl(method = "repeatedcv", number = 5, repeats = 3)

model3 <- train(depression ~ group + age + anxious_attachment + avoidant_attachment + isolation_reverse_scored + over_identification_reverse_scored + anxiety, data = psyc.train, method ="lm", trControl = train.control)
summary(model3)
pred2 <- predict(model3, newdata = psyc.test)
mean((psyc.test$depression-pred2)^2)
```

regression tree
```{r}
tree_psyc <- tree(depression ~ ., psyc.train)
summary(tree_psyc)
```

```{r}
plot(tree_psyc)
text(tree_psyc, pretty = 0)
```

```{r}
set.seed(9)
cv_psyc  <-  cv.tree(tree_psyc)
plot(cv_psyc$size, cv_psyc$dev, type = 'b')

prune_psyc  <-  prune.tree(tree_psyc,
                             best = 5)
plot(prune_psyc)
text(prune_psyc, pretty = 0)
```

```{r}
pred3  <-  predict(prune_psyc,newdata = psyc.test)

mean((pred3 - psyc.test$depression)^2)
```

Random Forests

```{r}
set.seed(1)
rf_psyc <- randomForest(depression ~ ., 
                           data = psyc.train,
                           mtry = 6,
                           importance = TRUE)
varImpPlot(rf_psyc)

bagged_estimate  <-  predict(rf_psyc, 
                             newdata = psyc.test)
mean((bagged_estimate - psyc.test$depression)^2)
```

